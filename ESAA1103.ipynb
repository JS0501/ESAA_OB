{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN033sa3kTsZKqAqhUZ95f/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JS0501/ESAA_OB/blob/main/ESAA1103.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 인공지능, 머신 러닝과 딥러닝**"
      ],
      "metadata": {
        "id": "gaac-xv-_RxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "인공지능은 인간의 지능을 모방하여 사람이 하는 일을 컴퓨터(기계)가 할 수 있도록 하는 기술이다.\n",
        "\n",
        "인공지능을 구현하는 방법으로 머신 러닝과 딥러닝이 있다.\n",
        "\n",
        "인공지능 > 머신 러닝 > 딥러닝\n",
        "\n",
        "머신 러닝과 딥러닝 모두 학습 모델을 제공하여 데이터를 분류할 수 있는 기술이다.\n",
        "\n",
        "- **머신 러닝**\n",
        "\n",
        "주어진 데이터를 인간이 먼저 처리(전처리)한다.\n",
        "\n",
        "이미지 데이터라면 사람이 학습 데이터를 컴퓨터가 인식할 수 있도록 준비해 두어야 한다.\n",
        "\n",
        "머신 러닝은 범용적인 목적을 위해 제작된 것으로 데이터의 특징을 스스로 추출하지 못한다.\n",
        "\n",
        "즉, 머신 러닝의 학습 과정은 각 데이터(혹은 이미지) 특성을 컴퓨터(기계)에 인식시키고 학습시켜 문제를 해결한다.\n",
        "\n",
        "- **딥러닝**\n",
        "\n",
        "인간이 하던 작업을 생략한다.\n",
        "\n",
        "대량의 데이터를 신경망에 적용하면 컴퓨터가 스스로 분석한 후 답을 찾는다."
      ],
      "metadata": {
        "id": "sjOYOlSa_UzW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 머신 러닝이란**"
      ],
      "metadata": {
        "id": "ozk_mHBSABAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "머신 러닝은 인공지능의 한 분야로, 컴퓨터 스스로 대용량 데이터에서 지식이나 패턴을 찾아 학습하고 예측을 수행하는 것이다.\n",
        "\n",
        "즉, 컴퓨터가 학습할 수 있게 하는 알고리즘과 기술을 개발하는 분야이다."
      ],
      "metadata": {
        "id": "ymvcmy_RAEse"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.1 머신 러닝 학습 과정**"
      ],
      "metadata": {
        "id": "_IbBIerpAOin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "머신 러닝은 크게 학습 단계(learning)와 예측 단계(prediction)으로 구분할 수 있다.\n",
        "\n",
        "훈련 데이터를 머신 러닝 알고리즘에 적용하여 학습시키고, 이 학습 결과로 모형이 생성된다.\n",
        "\n",
        "예측 단계에서는 학습 단계에서 생성된 모형에 새로운 데이터를 적용하여 결과를 예측한다.\n",
        "\n",
        "**특성 추출**\n",
        "\n",
        "머신 러닝에서 컴퓨터가 스스로 학습하려면, 즉 컴퓨터가 입력 받은 데이터를 분석하여 일정한 패턴이나 규칙을 찾아내려면 사람이 인지하는 데이터를 컴퓨터가 인지할 수 있는 데이터로 변환해 주어야 한다.\n",
        "\n",
        "이때 데이터별로 어떤 특징을 가지고 있는지 찾아내고, 그것을 토대로 데이터를 벡터로 변환하는 작업을 특성 추출(feature extraction)이라고 한다.\n",
        "\n",
        "**훈련과 검증, 테스트 데이터셋**\n",
        "\n",
        "수집된 데이터셋은 크게 훈련(training)과 테스트(test) 데이터셋으로 분리하여 사용된다.\n",
        "\n",
        "종종 훈련 데이터셋을 다시 훈련과 검증(validation) 용도로 분리해서 사용한다.\n",
        "\n",
        "검증 데이터셋을 사용하는 이유는 모델 성능을 평가하기 위해서이다.\n",
        "\n",
        "즉, 훈련 데이터셋으로 모델을 학습시킨 후 모델이 잘 예측하는지 그 성능을 평가하기 위해서 사용한다.\n",
        "\n",
        "하지만 검증 용도의 데이터셋은 훈련 데이터셋의 일부를 떼어서 사용하기 때문에 학습에 사용되는 데이터셋의 양이 많지 않다면 검증 데이터셋을 사용하는 것은 좋지 않다.\n",
        "\n",
        "모델의 성능 평가는 왜 필요할까?\n",
        "\n",
        "1) 테스트 데이터셋에 대한 성능을 가늠해볼 수 있다.\n",
        "\n",
        "2) 모델 성능을 높이는 데 도움을 준다.\n",
        "\n",
        "예를 들어 훈련 데이터셋에 대한 정확도는 높은데 검증 데이터셋에 대한 정확도가 낮다면 훈련 데이터셋에 과적합이 일어났을 가능성이 있다.\n",
        "\n",
        "이 경우 정규화(regularization)를 하거나 에포크(epoch)를 줄이는 방식으로 과적합을 막을 수 있다."
      ],
      "metadata": {
        "id": "rIF9ORx8AR3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.2 머신 러닝 학습 알고리즘**"
      ],
      "metadata": {
        "id": "ltJ-qVnRBleZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "머신 러닝의 학습 알고리즘으로는 지도 학습, 비지도 학습, 강화 학습이 있다.\n",
        "\n",
        "**지도 학습**\n",
        "\n",
        "정답이 무엇인지 컴퓨터에 알려 주고 학습시키는 방법이다.\n",
        "\n",
        "**비지도 학습**\n",
        "\n",
        "정답을 알려 주지 않고 비슷한 데이터를 클러스터링(범주화)하여 예측하는 학습 방법이다.\n",
        "\n",
        "유사도 기반(데이터 간 거리 측정)으로 특징이 유사한 데이터끼리 클러스터링으로 묶어서 분류한다.\n",
        "\n",
        "**강화 학습**\n",
        "\n",
        "분류할 수 있는 데이터가 있는 것도 아니고 데이터가 있다고 해도 정답이 없다.\n",
        "\n",
        "강화 학습은 자신의 행동에 대한 보상을 받으며 학습을 진행한다.\n",
        "\n",
        "보상이 커지는 행동은 자주 하도록 하고, 줄어드는 행동은 덜 하도록 하여 학습을 진행한다."
      ],
      "metadata": {
        "id": "-kpwpvOhBoSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3 딥러닝이란**"
      ],
      "metadata": {
        "id": "OuwlIiZWCG11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "딥러닝은 인간의 신경망 원리를 모방한 심층 신경망 이론을 기반으로 고안된 머신 러닝 방법의 일종이다.\n",
        "\n",
        "즉, 딥러닝이 머신 러닝과 다른 큰 차이점은 인간의 뇌를 기초로 하여 설계했다는 것이다."
      ],
      "metadata": {
        "id": "VyKCJqyeCIsO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.3.1 딥러닝 학습 과정**"
      ],
      "metadata": {
        "id": "83vjDlcFCRKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) 데이터 준비\n",
        "\n",
        "2) 모델(모형) 정의\n",
        "\n",
        "3) 모델(모형) 컴파일\n",
        "\n",
        "활성화 함수, 손실 함수, 옵티마이저 선택\n",
        "\n",
        "4) 모델(모형) 훈련\n",
        "\n",
        "5) 모델(모형) 예측"
      ],
      "metadata": {
        "id": "XB-OQwNkCSz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "딥러닝 학습 과정에서 중요한 핵심 구성 요소는 신경망과 역전파이다.\n",
        "\n",
        "딥러닝은 머신 러닝의 한 분야이기는 하지만, 심층 신경망을 사용한다는 점에서 머신 러닝과 차이가 있다.\n",
        "\n",
        "심층 신경망에는 데이터셋의 어떤 특성들이 중요한지 스스로에게 가르쳐 줄 수 있는 기능이 있다.\n",
        "\n",
        "또한, 가중치 값을 업데이트하기 위한 역전파가 중요하다.\n",
        "\n",
        "특히 역전파 계산 과정에서 사용되는 미분(오차를 각 가중치로 미분)이 성능에 미치는 주요한 요소이다."
      ],
      "metadata": {
        "id": "TwxiM6aoClhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.3.2 딥러닝 학습 알고리즘**"
      ],
      "metadata": {
        "id": "gBk_zlGNC1tI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "딥러닝 학습 알고리즘은 활용 분야에 따라 지도 학습과 비지도 학습, 전이 학습으로 분류된다.\n",
        "\n",
        "**지도 학습**\n",
        "\n",
        "컴퓨터 비전에서 가장 많이 사용되는 것: 합성곱 신경망\n",
        "\n",
        "시계열 데이터를 분류할 때 사용되는 것: 순환 신경망\n",
        "\n",
        "**비지도 학습**\n",
        "\n",
        "워드 임베딩, 군집\n",
        "\n",
        "**전이 학습**\n",
        "\n",
        "사전에 학습이 완료된 모델을 가지고 우리가 원하는 학습에 미세 조정 기법을 이용하여 학습시키는 방법이다.\n",
        "\n",
        "따라서 전이 학습은 사전에 학습이 완료된 모델이 필요하며, 학습이 완료된 모델을 어떻게 활용하는지에 대한 접근 방법이 필요하다.\n",
        "\n",
        "**사전 학습 모델**\n",
        "\n",
        "풀고자 하는 문제와 비슷하면서 많은 데이터로 이미 학습이 되어 있는 모델이다."
      ],
      "metadata": {
        "id": "42n04M_MC45g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1 파이토치 개요**"
      ],
      "metadata": {
        "id": "rRyF5hVgDmdn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.1 파이토치 특징 및 장점**"
      ],
      "metadata": {
        "id": "194K5AXiDqQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU에서 텐서 조작 및 동적 신경망 구축이 가능한 프레임워크\n",
        "\n",
        "- GPU: 연산 속도를 빠르게 하는 역할\n",
        "\n",
        "- 텐서(Tensor): 파이토치의 데이터 형태, 단일 데이터 형식으로 된 자료들의 다차원 행렬\n",
        "\n",
        "- 동적 신경망: 훈련을 반복할 때마다 네트워크 변경이 가능한 신경망. 예를 들어 학습 중에 은닉층을 추가하거나 제거하는 등 모델의 네트워크 조작이 가능."
      ],
      "metadata": {
        "id": "aRG-xp6mDt_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.2 파이토치의 아키텍처**"
      ],
      "metadata": {
        "id": "5Y9F9Rr6EDkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "크게 세 개의 계층으로 나뉜다.\n",
        "\n",
        "가장 상위 계층은 파이토치 API가 위치해 있으며 그 아래에는 파이토치 엔진이 있다.\n",
        "\n",
        "파이토치 엔진에서는 다차원 텐서 및 자동 미분을 처리한다.\n",
        "\n",
        "그리고 마지막으로 가장 아래에는 텐서에 대한 연산을 처리한다.\n",
        "\n",
        "CPU/GPU를 이용하는 텐서의 실질적인 계산을 위한, C, CUDA 등 라이브러리가 위치한다."
      ],
      "metadata": {
        "id": "XEvWJX3-EGTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2 파이토치 기본 문법**"
      ],
      "metadata": {
        "id": "WRtEdPA8EVwz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.1 텐서 다루기**"
      ],
      "metadata": {
        "id": "zMg3tKHYEadx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**텐서 생성 및 변환**\n",
        "\n",
        "텐서는 파이토치의 가장 기본이 되는 데이터 구조이다.\n",
        "\n",
        "넘파이의 ndarray와 비슷하여 GPU에서의 연산도 가능하다."
      ],
      "metadata": {
        "id": "pR3v5hDsEcAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서 생성"
      ],
      "metadata": {
        "id": "O1R-HUg2Ekcr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtSgBSNp_Oxb",
        "outputId": "76b7cc58-4f4d-43af-f613-2c44216fadb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.tensor([[1,2],[3,4]])) # 2차원 형태의 텐서 생성\n",
        "# print(torch.tensor([[1,2],[3,4]],device='cuda:O')) # GPU에 텐서 생성\n",
        "print(torch.tensor([[1,2],[3,4]],dtype=torch.float64)) # dtype을 이용하여 텐서 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서를 ndarray로 변환"
      ],
      "metadata": {
        "id": "KXvxDnj2FbIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([[1,2],[3,4]])\n",
        "print(temp.numpy()) # 텐서를 ndarray로 변환"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9Z0jTbCEl0K",
        "outputId": "6a7e4d70-5528-4877-99d4-6456582d6cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# temp = torch.tensor([[1,2],[3,4]],device='cuda:O')\n",
        "# print(temp.to('cpu').numpy()) # GPU상의 텐서를 CPU의 텐서로 변환한 후 ndarray로 변환"
      ],
      "metadata": {
        "id": "tE6rjfugFg0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**텐서의 인덱스 조작**\n",
        "\n",
        "넘파이의 ndarray를 조작하는 것과 유사하게 동작하기 때문에 배열처럼 인덱스를 바로 지정하거나 슬라이스 등을 사용할 수 있다."
      ],
      "metadata": {
        "id": "JmjPTEOOFtyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.FloatTensor([1,2,3,4,5,6,7]) # 파이토치로 1차원 벡터 생성\n",
        "print(temp[0],temp[1],temp[-1]) # 인덱스로 접근\n",
        "print('---------------------')\n",
        "print(temp[2:5],temp[4:-1]) # 슬라이스로 접근"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE-SqPS3FroM",
        "outputId": "470fb2dc-7bfd-4b11-a3ce-9ef61f2662fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.) tensor(2.) tensor(7.)\n",
            "---------------------\n",
            "tensor([3., 4., 5.]) tensor([5., 6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**텐서 연산 및 차원 조작**\n",
        "\n",
        "텐서는 넘파이의 ndarray처럼 다양한 수학 연산이 가능하며, GPU를 사용하면 더 빠르게 연산할 수 있다.\n",
        "\n",
        "참고로 텐서 간의 타입이 다르면 연산이 불가능하다.\n",
        "\n",
        "예를 들어 FloatTensor와 DoubleTensor 간에 사칙 연산을 수행하면 오류가 발생한다."
      ],
      "metadata": {
        "id": "6Z0tmzX6GFce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = torch.tensor([1,2,3]) # 길이가 3인 벡터 생성\n",
        "w = torch.tensor([3,4,6])\n",
        "print(w-v) # 길이가 같은 벡터 간 뺄셈 연산"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xAjnXblGBSr",
        "outputId": "d8ab80c7-4561-49eb-d9fc-bfa449ee2c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서의 차원을 조작한다.\n",
        "\n",
        "텐서의 차원에 대한 문제는 신경망에서 자주 다루어지므로 상당히 중요하다.\n",
        "\n",
        "텐서의 차원을 변경하는 가장 대표적인 방법은 view를 이용하는 것이다."
      ],
      "metadata": {
        "id": "noZ-uKUzGg5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([\n",
        "    [1,2],[3,4]]) # 2x2 행렬 생성\n",
        "print(temp.shape)\n",
        "print('--------------------')\n",
        "print(temp.view(4,1)) # 2x2 행렬을 4x1로 변형\n",
        "print('--------------------')\n",
        "print(temp.view(-1)) # 2x2 행렬을 1차원 벡터로 변형\n",
        "print('--------------------')\n",
        "print(temp.view(1,-1)) # -1은 (1,?)와 같은 의미로 다른 차원으로부터 해당 값을 유추하겠다는 것이다. 즉 (1,4)가 된다.\n",
        "print('--------------------')\n",
        "print(temp.view(-1,1)) # (4,1)이 된다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV0g2IH-Ga0K",
        "outputId": "f71fb45a-954f-4ce3-cdc8-4bc2d040b40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n",
            "--------------------\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n",
            "--------------------\n",
            "tensor([1, 2, 3, 4])\n",
            "--------------------\n",
            "tensor([[1, 2, 3, 4]])\n",
            "--------------------\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.2 데이터 준비**"
      ],
      "metadata": {
        "id": "DhEIKiKnHJmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**단순하게 파일을 불러와서 사용**"
      ],
      "metadata": {
        "id": "m4c5-Y_OHwxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "# data = pd.read_csv('../class2.csv')\n",
        "\n",
        "# x = torch.from_numpy(data['x'].values).unsqueeze(dim=1).float() # CSV 파일의 x 칼럼의 값을 넘파이 배열로 받아 Tensor(dtype)으로 바꾼다.\n",
        "# y = torch.from_numpy(data['y'].values).unsqueeze(dim=1).float()"
      ],
      "metadata": {
        "id": "ZDL9Dpg0HHox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**커스텀 데이터셋을 만들어서 사용**"
      ],
      "metadata": {
        "id": "nYd_nXtgHzCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class CustomDataset(torch.utils.data.Dataset):\n",
        "# def __init__(self): # 필요한 변수를 선언하고, 데이터셋의 전처리를 해 주는 함수\n",
        "# def __len__(self): # 데이터셋의 길이. 즉, 총 샘플의 수를 가져오는 함수\n",
        "# def __getitem__(self,index): # 데이터셋에서 특정 데이터를 가져오는 함수"
      ],
      "metadata": {
        "id": "0OvPDE2ZH0cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import torch\n",
        "# from torch.utils.data import Dataset\n",
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "# class CustomDataset(Dataset):\n",
        "#  def __init__(self,csv_file): # csv_file 파라미터를 통해 데이터셋을 불러온다.\n",
        "#    self.label = pd.read_csv(csv_file)\n",
        "#  def __len__(self): # 전체 데이터셋의 크기를 반환한다.\n",
        "#    return len(self.label)\n",
        "#  def __getitem__(self,idx): # 전체 x와 y 데이터 중에 해당 idx번째의 데이터를 가져온다.\n",
        "#    sample = torch.tensor(self.label.iloc[idx,0:3]).int()\n",
        "#    label = torch.tensor(self.label.iloc[idx,3]).int()\n",
        "#    return sample, label\n",
        "# tensor_dataset = CustomDataset('../covtype.csv') # 데이터셋으로 covtype.csv를 사용한다.\n",
        "# dataset = DataLoader(tensor_dataset,batch_size=4,shuffle=True) # 데이터셋을 torch.utils.data.DataLoader에 파라미터로 전달한다."
      ],
      "metadata": {
        "id": "ebKT51HCH84G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터로더"
      ],
      "metadata": {
        "id": "2SDUPx3vI_ZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, data in enumerate(dataset,0):\n",
        "#   print(i,end='')\n",
        "#   batch = data[0]\n",
        "#   print(batch.size())"
      ],
      "metadata": {
        "id": "1nMga7cxI9vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**파이토치에서 제공하는 데이터셋 사용**"
      ],
      "metadata": {
        "id": "E8OgawRQJIjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torchvision.transforms as transforms\n",
        "\n",
        "# mnist_transform = transforms.Compose([\n",
        "#    transforms.ToTensor(),\n",
        "#    transforms.Normalize((0.5,),(1.0,))\n",
        "#]) # 평균이 0.5, 표준편차가 1.0이 되도록 데이터의 분포(normalize)를 조정\n",
        "\n",
        "# from torchvision.datasets import MNIST\n",
        "# import request\n",
        "# download_root = '../chap02/data/MNIST_DATASET' # 내려받을 경로 지정\n",
        "# train_dataset = MNIST(download_root,transform=mnist_transform,train=True,downloae=True) # 훈련 데이터셋\n",
        "# valid_dataset = MNIST(download_root,transform=mnist_transform,train=FALSE,downloae=True) # 검증 데이터셋\n",
        "# test_dataset = MNIST(download_root,transform=mnist_transform,train=FALSE,downloae=True) # 테스트 데이터셋"
      ],
      "metadata": {
        "id": "DaHdNT54JLze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.3 모델 정의**"
      ],
      "metadata": {
        "id": "4Eai09xeJ3-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 계층: 모듈 또는 모듈을 구성하는 한 개의 계층으로 합성곱층, 선형 계층 등이 있다.\n",
        "\n",
        "- 모듈: 한 개 이상의 계층이 모여서 구성된 것으로, 모듈이 모여 새로운 모듈을 만들수도 있다.\n",
        "\n",
        "- 모델: 최종적으로 원하는 네트워크로, 한 개의 모듈이 모델이 될 수도 있다."
      ],
      "metadata": {
        "id": "Lj2MvcKZJ7vn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**단순 신경망을 정의하는 방법**"
      ],
      "metadata": {
        "id": "aaVG0AXfKFys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = nn.Linear(in_features=1,out_features=1,bias=True)"
      ],
      "metadata": {
        "id": "0TzbQT8XJ2Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nn.Module()을 상속하여 정의하는 방법**"
      ],
      "metadata": {
        "id": "ud0C2x9SKL_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class MLP(Module):\n",
        "#   def __init__(self,inputs):\n",
        "#      super(MLP,self).__init__()\n",
        "#      self.layer Linear(inputs,1) # 계층 정의\n",
        "#      self.activation = Sigmoid() # 활성화 함수 정의\n",
        "#   def forward(self,X):\n",
        "#      X = self.layer(X)\n",
        "#      X = self.activation(X)\n",
        "#      return X"
      ],
      "metadata": {
        "id": "3Jzg0e4BKKaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sequential 신경망을 정의하는 방법**"
      ],
      "metadata": {
        "id": "bM0t0uT5Kjeb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Sequential을 사용하면 __init__()에서 사용할 네트워크 모델들을 정의해 줄 뿐만 아니라 forward() 함수에서는 모델에서 실행되어야 할 계산을 좀 더 가독성이 뛰어나게 코드로 작성할 수 있다.\n",
        "\n",
        "또한, Sequential 객체는 그 안에 포함된 각 모듈을 순차적으로 실행해준다."
      ],
      "metadata": {
        "id": "HZGhuqzmKsJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MLP,self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3,out_channels=64,kernel_size=5),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(2))\n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=64,out_channels=30,kernel_size=5),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(2))\n",
        "\n",
        "    self.layer3 = nn.Sequential(\n",
        "        nn.Linear(in_features=30*5*5,out_features=10,bias=True),\n",
        "        nn.ReLU(inplace=True))\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = self.layer1(x)\n",
        "      x = self.layer2(x)\n",
        "      x = x.view(x.shape[0],-1)\n",
        "      x = self.layer3(x)\n",
        "      return x\n",
        "\n",
        "    model = MLP() # 모델에 대한 객체 생성\n",
        "\n",
        "    print(\"Printing children\\n------------------------------------\")\n",
        "    print(list(model.children()))\n",
        "    print(\"\\n\\nPrinting Modules\\n---------------------------------\")\n",
        "    print(list(model.modules()))"
      ],
      "metadata": {
        "id": "1POAUsokKiUv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Sequential은 모델의 계층이 복잡할수록 효과가 뛰어나다."
      ],
      "metadata": {
        "id": "lZHfsL-sw-oM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**함수로 신경망을 정의하는 방법**"
      ],
      "metadata": {
        "id": "q894gHdPxCag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MLP(in_features=1, hidden_features=20, out_features=1):\n",
        "  hidden = nn.Linear(in_features=in_features, out_features=hidden_features, bias=True)\n",
        "  activation = nn.ReLU()\n",
        "  output = nn.Linear(in_features=hidden_features, out_features=out_features, bias=True)\n",
        "  net = nn.Sequential(hidden,activation,output)\n",
        "  return net"
      ],
      "metadata": {
        "id": "RfhkaIumwyVj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.4 모델의 파라미터 정의**"
      ],
      "metadata": {
        "id": "X8J9b7JqxYno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 손실 함수: 학습하는 동안 출력과 실제 값(정답) 사이의 오차를 측정한다.\n",
        "\n",
        "- 옵티마이저: 데이터와 손실 함수를 바탕으로 모델의 업데이트 방법을 결정한다.\n",
        "\n",
        "- 학습률 스케줄러: 미리 지정한 횟수의 에포크를 지날 때마다 학습률을 감소시킨다. 학습률 스케줄러를 이용하면 학습 초기에는 빠른 학습을 진행하다가 전역 최소점 근처에 다다르면 학습률을 줄여서 최적점을 찾아갈 수 있도록 한다.\n",
        "\n",
        "- 지표: 훈련과 테스트 단계를 모니터링한다."
      ],
      "metadata": {
        "id": "IzEPgIvAxcN7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 파라미터를 정의하는 예시 코드"
      ],
      "metadata": {
        "id": "BFolDlqnx5rV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.optim import optimizer\n",
        "# criterion = torch.nn.MSELoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.9)\n",
        "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer,lr_lambda=lambda epoch:0.95**epoch)\n",
        "# for epoch in range(1,100+1)\n",
        "#    for x,y in dataloader:\n",
        "#       optimizer.zero_grad()\n",
        "# loss_fn(model(x),y).backward()\n",
        "# optimizer.step()\n",
        "# scheduler.step()"
      ],
      "metadata": {
        "id": "XOHEaEGLxX8O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.5 모델 훈련**"
      ],
      "metadata": {
        "id": "mL8d7GSjya--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for epoch in range(100):\n",
        "#    yhat = model(x_train)\n",
        "#    loss = criterion(yhat,y_train)\n",
        "#    optimizer.zero_grad() # 오차가 중첩적으로 쌓이지 않도록 초기화\n",
        "#    loss.backward()\n",
        "#    optimizer.step()"
      ],
      "metadata": {
        "id": "Bvcff9iMyahB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.6 모델 평가**"
      ],
      "metadata": {
        "id": "5wWgV-rZyryw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "오류 때문에 주석 처리했습니다."
      ],
      "metadata": {
        "id": "Xh41PtVj1AHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchmetrics\n",
        "\n",
        "preds = torch.randn(10,5).softmax(dim=-1)\n",
        "target = torch.randint(5,(10,))\n",
        "\n",
        "# acc = torchmetrics.functional.accuracy(preds,target)"
      ],
      "metadata": {
        "id": "cNjDsglPyx5m"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torchmetrics\n",
        "# metric = torchmetrics.Accuracy() # 모델 평가(정확도) 초기화\n",
        "\n",
        "# n_batches = 10\n",
        "# for i in range(n_batches):\n",
        "#    preds = torch.randn(10,5).softmax(dim=-1)\n",
        "#    target = torch.randint(5,(10,))\n",
        "\n",
        "#    acc = metric(preds,target)\n",
        "#    print(f\"Accuracy on batch {i}: {acc}\") # 현재 배치에서 모델 평가(정확도)\n",
        "\n",
        "# acc = metric.compute()\n",
        "# print(f\"Accuracy on all data: {acc}\") # 모든 배치에서 모델 평가(정확도)"
      ],
      "metadata": {
        "id": "nMq3iTtny9dY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.7 훈련 과정 모니터링**"
      ],
      "metadata": {
        "id": "ySZ8SngYzoSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "# writer = SummaryWriter('../chap02/tensorboard') # 모니터링에 필요한 값들이 저장될 위치\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#    model.train() # 학습 모드로 전환(dropout=True)\n",
        "#    batch_loss = 0.0\n",
        "\n",
        "#    for i, (x,y) in enumerate(dataloader):\n",
        "#       x,y = x.to(device).float(), y.to(device).float()\n",
        "#       outputs = model(x)\n",
        "#       loss = criterion(outputs,y)\n",
        "#       writer.add_scalar(\"Loss\",loss,epoch) # 스칼라 값(오차)을 기록\n",
        "#       optimizer.zero_grad()\n",
        "#       loss.backward()\n",
        "#       optimizer.step()\n",
        "# writer.close() # SummaryWriter가 더 이상 필요하지 않으면 close() 메서드 호출"
      ],
      "metadata": {
        "id": "MZRPzvydzncH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tCbTAcsA0QmT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}